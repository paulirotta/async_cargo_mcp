use async_cargo_mcp::test_cargo_tools;
use std::time::Instant;

mod common;
use common::test_project::create_basic_project;

/// Performance benchmark demonstrating shell pool improvements
/// This test measures execution times to verify the shell pool system provides
/// performance benefits in real usage scenarios
// This performance benchmark is valuable but slow; ignore by default to speed CI and local runs.
// Run manually with: cargo nextest run -E 'test(benchmark_shell_pool_performance)'
#[tokio::test]
#[ignore]
async fn benchmark_shell_pool_performance() {
    println!("ðŸš€ Starting Shell Pool Performance Benchmark");
    println!("============================================");

    // Create a test project
    let temp_project = create_basic_project()
        .await
        .expect("Failed to create test project");
    let project_path = temp_project.path().to_str().unwrap();

    println!("Testing in directory: {}", project_path);

    // Test scenarios: multiple operations in sequence
    let operations = vec![
        ("check", "Cargo check validation"),
        ("build", "Full project compilation"),
        ("check", "Subsequent check (should be faster with shells)"),
    ];

    const ITERATIONS: usize = 2;
    let mut results = Vec::new();

    for (op_name, op_desc) in &operations {
        println!("\nðŸ“Š Benchmarking: {} - {}", op_name, op_desc);
        println!("------------------------");

        let mut times = Vec::new();

        for i in 0..ITERATIONS {
            let start = Instant::now();
            let result = match *op_name {
                "check" => test_cargo_tools::test_check_command(project_path).await,
                "build" => test_cargo_tools::test_build_command(project_path).await,
                _ => panic!("Unsupported operation: {}", op_name),
            };
            let duration = start.elapsed();
            times.push(duration);

            assert!(
                result.is_ok(),
                "{} operation {} failed: {:?}",
                op_name,
                i + 1,
                result
            );
            println!(
                "{} operation {} completed in {:?}",
                op_name,
                i + 1,
                duration
            );
        }

        let avg_time = times.iter().sum::<std::time::Duration>() / ITERATIONS as u32;
        let min_time = times.iter().min().unwrap();
        let max_time = times.iter().max().unwrap();

        println!(
            "Average: {:?}, Min: {:?}, Max: {:?}",
            avg_time, min_time, max_time
        );

        results.push((op_name, op_desc, avg_time, *min_time, *max_time));
    }

    // Summary report
    println!("\nðŸ“ˆ PERFORMANCE BENCHMARK RESULTS");
    println!("================================");

    for (op, desc, avg, min, max) in &results {
        println!(
            "{:>6}: {} - Avg: {:?}, Range: {:?} - {:?}",
            op, desc, avg, min, max
        );
    }

    // Performance analysis
    if results.len() >= 3 {
        let first_check = &results[0]; // Initial check
        let build_time = &results[1]; // Full build
        let second_check = &results[2]; // Subsequent check

        let speedup = first_check.2.as_nanos() as f64 / second_check.2.as_nanos() as f64;

        println!("\nðŸŽ¯ SHELL POOL ANALYSIS:");
        println!("First check: {:?}", first_check.2);
        println!("After build check: {:?}", second_check.2);
        if speedup > 1.0 {
            println!(
                "Improvement: {:.2}x faster for subsequent operations",
                speedup
            );
        }

        // Validate that all operations completed successfully (no zero durations)
        assert!(
            first_check.2.as_millis() > 0,
            "Check operations should have measurable duration"
        );
        assert!(
            build_time.2.as_millis() > 0,
            "Build operations should have measurable duration"
        );
        assert!(
            second_check.2.as_millis() > 0,
            "Subsequent check operations should have measurable duration"
        );

        println!("ðŸ“ˆ PERFORMANCE CHARACTERISTICS:");
        println!("  - All operations completed successfully");
        println!("  - Shell pool system is operational");
    }

    println!("\nâœ… Performance Benchmark Completed!");
    println!("Shell pool system is operational and providing optimized command execution.");
}

/// Benchmark focused on measuring command startup overhead
// This startup overhead benchmark is also slow; ignore by default. Run with filter as needed.
#[tokio::test]
#[ignore]
async fn benchmark_command_startup_overhead() {
    println!("âš¡ Command Startup Overhead Benchmark");
    println!("====================================");

    // Create a test project
    let temp_project = create_basic_project()
        .await
        .expect("Failed to create test project");
    let project_path = temp_project.path().to_str().unwrap();

    // Run a series of quick check operations to measure startup overhead
    const STARTUP_TESTS: usize = 5;
    let mut startup_times = Vec::new();

    println!(
        "Running {} quick check operations to measure startup overhead...",
        STARTUP_TESTS
    );

    for i in 0..STARTUP_TESTS {
        let start = Instant::now();
        let result = test_cargo_tools::test_check_command(project_path).await;
        let duration = start.elapsed();
        startup_times.push(duration);

        assert!(
            result.is_ok(),
            "Startup test {} failed: {:?}",
            i + 1,
            result
        );
        println!("Startup test {}: {:?}", i + 1, duration);
    }

    // Calculate statistics
    let avg_startup = startup_times.iter().sum::<std::time::Duration>() / STARTUP_TESTS as u32;
    let min_startup = startup_times.iter().min().unwrap();
    let max_startup = startup_times.iter().max().unwrap();

    println!("\nStartup Overhead Statistics:");
    println!("Average: {:?}", avg_startup);
    println!("Min: {:?}", min_startup);
    println!("Max: {:?}", max_startup);

    // Performance expectations for shell pools
    // With shell pools, subsequent operations should be much faster than the first
    if startup_times.len() >= 3 {
        let first_run = startup_times[0];
        let later_avg = startup_times[2..].iter().sum::<std::time::Duration>()
            / (startup_times.len() - 2) as u32;

        println!("First run: {:?}", first_run);
        println!("Later runs average: {:?}", later_avg);

        // Note: In a real shell pool environment, we'd expect later_avg to be significantly
        // smaller than first_run due to shell reuse
    }

    println!("âœ… Command Startup Overhead Benchmark Completed!");
}
